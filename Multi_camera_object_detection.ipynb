{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALLING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmbOmSFWYIHL",
    "outputId": "9c20e9aa-75ee-4e06-d7ba-9eff56beea27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (8.3.168)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (2.7.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
      "Requirement already satisfied: filelock in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: deep_sort_realtime in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from deep_sort_realtime) (2.1.3)\n",
      "Requirement already satisfied: scipy in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from deep_sort_realtime) (1.15.3)\n",
      "Requirement already satisfied: opencv-python in /Users/saikrishnasarangan/Documents/anaconda/anaconda3/lib/python3.13/site-packages (from deep_sort_realtime) (4.12.0.88)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install deep_sort_realtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First version  (Tried this one but it is not working. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x640 12 cars, 2 trucks, 2 traffic lights, 1226.8ms\n",
      "Speed: 2.2ms preprocess, 1226.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 2 traffic lights, 1267.4ms\n",
      "Speed: 1.6ms preprocess, 1267.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 2 trucks, 2 traffic lights, 1192.6ms\n",
      "Speed: 1.5ms preprocess, 1192.6ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 2 traffic lights, 1089.5ms\n",
      "Speed: 1.5ms preprocess, 1089.5ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 2 trucks, 2 traffic lights, 1144.3ms\n",
      "Speed: 1.6ms preprocess, 1144.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 2 trucks, 2 traffic lights, 1266.7ms\n",
      "Speed: 1.6ms preprocess, 1266.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 2 trucks, 2 traffic lights, 1355.1ms\n",
      "Speed: 1.5ms preprocess, 1355.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 2 trucks, 2 traffic lights, 915.3ms\n",
      "Speed: 1.7ms preprocess, 915.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 2 trucks, 2 traffic lights, 1012.0ms\n",
      "Speed: 1.6ms preprocess, 1012.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 2 trucks, 2 traffic lights, 938.4ms\n",
      "Speed: 1.8ms preprocess, 938.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 924.2ms\n",
      "Speed: 1.6ms preprocess, 924.2ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1666.7ms\n",
      "Speed: 1.5ms preprocess, 1666.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1294.0ms\n",
      "Speed: 1.6ms preprocess, 1294.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1051.8ms\n",
      "Speed: 1.5ms preprocess, 1051.8ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1112.4ms\n",
      "Speed: 1.6ms preprocess, 1112.4ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1394.0ms\n",
      "Speed: 1.9ms preprocess, 1394.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1682.8ms\n",
      "Speed: 1.6ms preprocess, 1682.8ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1096.7ms\n",
      "Speed: 1.5ms preprocess, 1096.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1306.5ms\n",
      "Speed: 1.8ms preprocess, 1306.5ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1246.5ms\n",
      "Speed: 1.6ms preprocess, 1246.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 1 bus, 1 truck, 1097.2ms\n",
      "Speed: 1.8ms preprocess, 1097.2ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 10 cars, 1 bus, 1 truck, 1015.6ms\n",
      "Speed: 1.6ms preprocess, 1015.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 10 cars, 1 bus, 1 truck, 1064.5ms\n",
      "Speed: 1.8ms preprocess, 1064.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 9 cars, 1 bus, 1 truck, 1037.5ms\n",
      "Speed: 1.6ms preprocess, 1037.5ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 8 cars, 1 bus, 1 truck, 1204.7ms\n",
      "Speed: 1.6ms preprocess, 1204.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 8 cars, 1 bus, 1 truck, 1102.0ms\n",
      "Speed: 1.5ms preprocess, 1102.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 8 cars, 1 bus, 1 truck, 1246.1ms\n",
      "Speed: 1.5ms preprocess, 1246.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 bus, 1 truck, 1450.5ms\n",
      "Speed: 1.6ms preprocess, 1450.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 bus, 1 truck, 1991.5ms\n",
      "Speed: 1.7ms preprocess, 1991.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 bus, 1 truck, 2824.5ms\n",
      "Speed: 1.5ms preprocess, 2824.5ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 1 fire hydrant, 1 stop sign, 2520.8ms\n",
      "Speed: 1.6ms preprocess, 2520.8ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 1 fire hydrant, 1 stop sign, 1353.6ms\n",
      "Speed: 2.0ms preprocess, 1353.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 1 fire hydrant, 1 stop sign, 1008.9ms\n",
      "Speed: 1.7ms preprocess, 1008.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 1 fire hydrant, 1 stop sign, 1034.9ms\n",
      "Speed: 1.7ms preprocess, 1034.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 1 truck, 1 fire hydrant, 1 stop sign, 886.6ms\n",
      "Speed: 1.6ms preprocess, 886.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 4 cars, 1 truck, 1 fire hydrant, 1 stop sign, 981.9ms\n",
      "Speed: 1.6ms preprocess, 981.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 4 cars, 1 truck, 1 stop sign, 1378.8ms\n",
      "Speed: 1.6ms preprocess, 1378.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 1 truck, 1 fire hydrant, 1 stop sign, 1572.9ms\n",
      "Speed: 1.5ms preprocess, 1572.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 4 cars, 1 truck, 1 fire hydrant, 1 stop sign, 1446.6ms\n",
      "Speed: 1.6ms preprocess, 1446.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 1 truck, 1 fire hydrant, 1 stop sign, 1594.1ms\n",
      "Speed: 1.8ms preprocess, 1594.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 truck, 1289.8ms\n",
      "Speed: 2.1ms preprocess, 1289.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 truck, 1252.0ms\n",
      "Speed: 1.6ms preprocess, 1252.0ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 truck, 1114.2ms\n",
      "Speed: 1.9ms preprocess, 1114.2ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 1247.6ms\n",
      "Speed: 1.8ms preprocess, 1247.6ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 1448.1ms\n",
      "Speed: 1.5ms preprocess, 1448.1ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 1070.0ms\n",
      "Speed: 1.7ms preprocess, 1070.0ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 truck, 946.8ms\n",
      "Speed: 1.5ms preprocess, 946.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 truck, 981.7ms\n",
      "Speed: 2.2ms preprocess, 981.7ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 truck, 1 bench, 1156.9ms\n",
      "Speed: 1.7ms preprocess, 1156.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 truck, 1440.7ms\n",
      "Speed: 1.7ms preprocess, 1440.7ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 1823.2ms\n",
      "Speed: 1.5ms preprocess, 1823.2ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 1705.2ms\n",
      "Speed: 1.6ms preprocess, 1705.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 2165.7ms\n",
      "Speed: 1.7ms preprocess, 2165.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 1443.8ms\n",
      "Speed: 2.1ms preprocess, 1443.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x640 13 cars, 2 trucks, 1355.2ms\n",
      "Speed: 4.1ms preprocess, 1355.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 2328.7ms\n",
      "Speed: 1.7ms preprocess, 2328.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 2611.9ms\n",
      "Speed: 1.6ms preprocess, 2611.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 916.9ms\n",
      "Speed: 1.6ms preprocess, 916.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 1160.1ms\n",
      "Speed: 1.6ms preprocess, 1160.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 1592.9ms\n",
      "Speed: 1.6ms preprocess, 1592.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 2 trucks, 2 stop signs, 1635.7ms\n",
      "Speed: 1.8ms preprocess, 1635.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 13 cars, 2 trucks, 2 stop signs, 1565.0ms\n",
      "Speed: 1.7ms preprocess, 1565.0ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 14 cars, 2 trucks, 2 stop signs, 1238.2ms\n",
      "Speed: 1.7ms preprocess, 1238.2ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 2 trucks, 1 stop sign, 1509.6ms\n",
      "Speed: 1.6ms preprocess, 1509.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 14 cars, 2 trucks, 1 stop sign, 1656.2ms\n",
      "Speed: 1.6ms preprocess, 1656.2ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 persons, 14 cars, 2 trucks, 1 stop sign, 1225.4ms\n",
      "Speed: 1.5ms preprocess, 1225.4ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 2 trucks, 1 stop sign, 1775.0ms\n",
      "Speed: 1.6ms preprocess, 1775.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 persons, 13 cars, 2 trucks, 1 stop sign, 906.0ms\n",
      "Speed: 1.5ms preprocess, 906.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 1 stop sign, 905.6ms\n",
      "Speed: 1.6ms preprocess, 905.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 13 cars, 2 trucks, 1 stop sign, 984.9ms\n",
      "Speed: 1.5ms preprocess, 984.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 1 truck, 1004.3ms\n",
      "Speed: 1.8ms preprocess, 1004.3ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 9 cars, 1 truck, 1580.4ms\n",
      "Speed: 1.5ms preprocess, 1580.4ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 9 cars, 1 truck, 2300.7ms\n",
      "Speed: 1.7ms preprocess, 2300.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 9 cars, 1 truck, 1961.3ms\n",
      "Speed: 2.0ms preprocess, 1961.3ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 1 truck, 1625.3ms\n",
      "Speed: 1.6ms preprocess, 1625.3ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 1 truck, 1427.5ms\n",
      "Speed: 1.5ms preprocess, 1427.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 cars, 1856.0ms\n",
      "Speed: 1.5ms preprocess, 1856.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 cars, 1 truck, 900.3ms\n",
      "Speed: 1.6ms preprocess, 900.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 1 truck, 901.1ms\n",
      "Speed: 2.2ms preprocess, 901.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 1 truck, 991.1ms\n",
      "Speed: 1.6ms preprocess, 991.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 1 traffic light, 885.1ms\n",
      "Speed: 1.8ms preprocess, 885.1ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 1 traffic light, 1247.8ms\n",
      "Speed: 1.6ms preprocess, 1247.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 1 traffic light, 1991.0ms\n",
      "Speed: 1.7ms preprocess, 1991.0ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 2 traffic lights, 2848.1ms\n",
      "Speed: 1.6ms preprocess, 2848.1ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 cars, 1 truck, 2 traffic lights, 1433.5ms\n",
      "Speed: 1.5ms preprocess, 1433.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 1 truck, 2 traffic lights, 1689.1ms\n",
      "Speed: 1.5ms preprocess, 1689.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 1 truck, 2 traffic lights, 2657.7ms\n",
      "Speed: 1.9ms preprocess, 2657.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 1 truck, 2 traffic lights, 890.8ms\n",
      "Speed: 1.6ms preprocess, 890.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 cars, 1 truck, 2 traffic lights, 1043.4ms\n",
      "Speed: 1.6ms preprocess, 1043.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 1 truck, 2 traffic lights, 874.0ms\n",
      "Speed: 1.6ms preprocess, 874.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 3 traffic lights, 886.4ms\n",
      "Speed: 1.6ms preprocess, 886.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 3 traffic lights, 1389.9ms\n",
      "Speed: 1.9ms preprocess, 1389.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 2 trucks, 3 traffic lights, 1236.3ms\n",
      "Speed: 1.6ms preprocess, 1236.3ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 1 truck, 3 traffic lights, 1308.0ms\n",
      "Speed: 1.8ms preprocess, 1308.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 1 truck, 3 traffic lights, 1241.2ms\n",
      "Speed: 2.7ms preprocess, 1241.2ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 1 truck, 3 traffic lights, 1330.8ms\n",
      "Speed: 1.7ms preprocess, 1330.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 1 truck, 3 traffic lights, 1115.6ms\n",
      "Speed: 1.6ms preprocess, 1115.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 1 truck, 3 traffic lights, 1385.1ms\n",
      "Speed: 1.5ms preprocess, 1385.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 1 truck, 3 traffic lights, 1055.7ms\n",
      "Speed: 10.6ms preprocess, 1055.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 cars, 3 traffic lights, 1440.3ms\n",
      "Speed: 1.5ms preprocess, 1440.3ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 cars, 1 truck, 1297.4ms\n",
      "Speed: 1.6ms preprocess, 1297.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 cars, 1 truck, 1457.7ms\n",
      "Speed: 1.9ms preprocess, 1457.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 cars, 1 truck, 899.3ms\n",
      "Speed: 1.9ms preprocess, 899.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 cars, 1 truck, 897.9ms\n",
      "Speed: 1.8ms preprocess, 897.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 cars, 1 truck, 868.6ms\n",
      "Speed: 1.6ms preprocess, 868.6ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 cars, 1 truck, 1257.8ms\n",
      "Speed: 1.6ms preprocess, 1257.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 cars, 1 truck, 1419.1ms\n",
      "Speed: 1.5ms preprocess, 1419.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 cars, 1 truck, 1212.3ms\n",
      "Speed: 1.8ms preprocess, 1212.3ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 cars, 1 truck, 1302.2ms\n",
      "Speed: 1.6ms preprocess, 1302.2ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 cars, 1 truck, 1102.4ms\n",
      "Speed: 1.7ms preprocess, 1102.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x640 19 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1086.4ms\n",
      "Speed: 1.6ms preprocess, 1086.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1529.5ms\n",
      "Speed: 1.8ms preprocess, 1529.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 990.4ms\n",
      "Speed: 1.7ms preprocess, 990.4ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 879.6ms\n",
      "Speed: 1.5ms preprocess, 879.6ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 890.6ms\n",
      "Speed: 1.6ms preprocess, 890.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 904.9ms\n",
      "Speed: 1.5ms preprocess, 904.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 944.7ms\n",
      "Speed: 1.6ms preprocess, 944.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 3438.9ms\n",
      "Speed: 1.5ms preprocess, 3438.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 2334.1ms\n",
      "Speed: 2.2ms preprocess, 2334.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 3437.0ms\n",
      "Speed: 2.1ms preprocess, 3437.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 cars, 4 trucks, 1 stop sign, 4288.3ms\n",
      "Speed: 1.5ms preprocess, 4288.3ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 cars, 4 trucks, 1 stop sign, 1103.6ms\n",
      "Speed: 1.8ms preprocess, 1103.6ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 cars, 3 trucks, 1 stop sign, 933.5ms\n",
      "Speed: 1.7ms preprocess, 933.5ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 cars, 4 trucks, 1 stop sign, 989.8ms\n",
      "Speed: 1.6ms preprocess, 989.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 cars, 3 trucks, 2 stop signs, 1234.4ms\n",
      "Speed: 1.5ms preprocess, 1234.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 cars, 3 trucks, 2 stop signs, 2717.5ms\n",
      "Speed: 1.5ms preprocess, 2717.5ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 cars, 3 trucks, 2 stop signs, 2916.1ms\n",
      "Speed: 1.7ms preprocess, 2916.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 cars, 3 trucks, 2 stop signs, 3054.9ms\n",
      "Speed: 1.5ms preprocess, 3054.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 cars, 4 trucks, 2 stop signs, 3682.2ms\n",
      "Speed: 1.7ms preprocess, 3682.2ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 cars, 4 trucks, 2 stop signs, 972.5ms\n",
      "Speed: 1.6ms preprocess, 972.5ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 967.2ms\n",
      "Speed: 1.8ms preprocess, 967.2ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1010.7ms\n",
      "Speed: 1.6ms preprocess, 1010.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 cars, 2 trucks, 1 fire hydrant, 1 stop sign, 1733.6ms\n",
      "Speed: 1.6ms preprocess, 1733.6ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 1 truck, 1 fire hydrant, 1 stop sign, 2508.1ms\n",
      "Speed: 1.6ms preprocess, 2508.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 1 truck, 1 fire hydrant, 1 stop sign, 1707.4ms\n",
      "Speed: 1.7ms preprocess, 1707.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 cars, 1 truck, 1 fire hydrant, 1 stop sign, 1922.1ms\n",
      "Speed: 1.5ms preprocess, 1922.1ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 1 truck, 1 fire hydrant, 1 stop sign, 2232.1ms\n",
      "Speed: 1.6ms preprocess, 2232.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 1 truck, 1 fire hydrant, 1 stop sign, 1979.3ms\n",
      "Speed: 2.1ms preprocess, 1979.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 cars, 1 truck, 1 fire hydrant, 1 stop sign, 2078.7ms\n",
      "Speed: 1.6ms preprocess, 2078.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 1 truck, 1 fire hydrant, 1 stop sign, 905.8ms\n",
      "Speed: 1.6ms preprocess, 905.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 1005.9ms\n",
      "Speed: 1.7ms preprocess, 1005.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 cars, 966.3ms\n",
      "Speed: 2.0ms preprocess, 966.3ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 1748.9ms\n",
      "Speed: 1.7ms preprocess, 1748.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 1 truck, 2368.2ms\n",
      "Speed: 1.5ms preprocess, 2368.2ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 cars, 1 truck, 1587.9ms\n",
      "Speed: 1.8ms preprocess, 1587.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 1 truck, 2165.8ms\n",
      "Speed: 1.6ms preprocess, 2165.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 1 truck, 2020.9ms\n",
      "Speed: 1.8ms preprocess, 2020.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 1 truck, 1945.5ms\n",
      "Speed: 1.5ms preprocess, 1945.5ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 14 cars, 1870.5ms\n",
      "Speed: 1.7ms preprocess, 1870.5ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 cars, 1 truck, 1215.7ms\n",
      "Speed: 1.6ms preprocess, 1215.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 cars, 1 truck, 1 traffic light, 880.3ms\n",
      "Speed: 1.5ms preprocess, 880.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 cars, 1 truck, 1 traffic light, 922.8ms\n",
      "Speed: 2.5ms preprocess, 922.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 cars, 1 truck, 1 traffic light, 987.0ms\n",
      "Speed: 1.6ms preprocess, 987.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 cars, 2 trucks, 1 traffic light, 1995.6ms\n",
      "Speed: 1.6ms preprocess, 1995.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 cars, 2 trucks, 1 traffic light, 1762.2ms\n",
      "Speed: 1.5ms preprocess, 1762.2ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 cars, 2 trucks, 1 traffic light, 1812.7ms\n",
      "Speed: 1.5ms preprocess, 1812.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 cars, 2 trucks, 1 traffic light, 1974.9ms\n",
      "Speed: 1.7ms preprocess, 1974.9ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 cars, 2 trucks, 1 traffic light, 2455.7ms\n",
      "Speed: 1.6ms preprocess, 2455.7ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 cars, 2 trucks, 2 traffic lights, 1827.0ms\n",
      "Speed: 1.6ms preprocess, 1827.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 cars, 1 truck, 2 traffic lights, 899.8ms\n",
      "Speed: 1.8ms preprocess, 899.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 1 bus, 1 truck, 910.8ms\n",
      "Speed: 1.6ms preprocess, 910.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 1 bus, 1 truck, 993.9ms\n",
      "Speed: 1.6ms preprocess, 993.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 cars, 1 bus, 1 truck, 1340.3ms\n",
      "Speed: 1.8ms preprocess, 1340.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 512x640 10 cars, 1 bus, 1 truck, 1746.2ms\n",
      "Speed: 1.5ms preprocess, 1746.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 cars, 1 bus, 1 truck, 1399.0ms\n",
      "Speed: 1.5ms preprocess, 1399.0ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 cars, 1 bus, 1 truck, 2077.0ms\n",
      "Speed: 1.5ms preprocess, 2077.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 cars, 1 bus, 1 truck, 2059.6ms\n",
      "Speed: 1.5ms preprocess, 2059.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 1 bus, 1 truck, 2603.4ms\n",
      "Speed: 1.6ms preprocess, 2603.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 1 bus, 1 truck, 1234.4ms\n",
      "Speed: 1.6ms preprocess, 1234.4ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 cars, 1 bus, 1 truck, 940.4ms\n",
      "Speed: 1.5ms preprocess, 940.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 persons, 13 cars, 3 trucks, 1 stop sign, 875.9ms\n",
      "Speed: 1.5ms preprocess, 875.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 persons, 15 cars, 3 trucks, 1 stop sign, 919.7ms\n",
      "Speed: 1.5ms preprocess, 919.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 persons, 14 cars, 3 trucks, 1 stop sign, 1103.9ms\n",
      "Speed: 1.6ms preprocess, 1103.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 14 cars, 2 trucks, 1 stop sign, 2055.0ms\n",
      "Speed: 1.6ms preprocess, 2055.0ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 14 cars, 2 trucks, 1 stop sign, 1964.0ms\n",
      "Speed: 1.5ms preprocess, 1964.0ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 15 cars, 2 trucks, 1 stop sign, 1403.0ms\n",
      "Speed: 1.6ms preprocess, 1403.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 17 cars, 2 trucks, 1 stop sign, 2287.1ms\n",
      "Speed: 1.6ms preprocess, 2287.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 15 cars, 2 trucks, 1 stop sign, 2017.4ms\n",
      "Speed: 1.7ms preprocess, 2017.4ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 16 cars, 2 trucks, 1 stop sign, 2769.9ms\n",
      "Speed: 2.3ms preprocess, 2769.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 17 cars, 2 trucks, 1 stop sign, 2034.4ms\n",
      "Speed: 2.6ms preprocess, 2034.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 18 cars, 7 trucks, 907.4ms\n",
      "Speed: 1.6ms preprocess, 907.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 19 cars, 7 trucks, 932.8ms\n",
      "Speed: 1.8ms preprocess, 932.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 19 cars, 7 trucks, 1020.9ms\n",
      "Speed: 1.6ms preprocess, 1020.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 20 cars, 7 trucks, 2018.9ms\n",
      "Speed: 1.8ms preprocess, 2018.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 17 cars, 7 trucks, 2244.1ms\n",
      "Speed: 1.5ms preprocess, 2244.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 17 cars, 7 trucks, 1703.1ms\n",
      "Speed: 1.6ms preprocess, 1703.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 18 cars, 7 trucks, 2185.5ms\n",
      "Speed: 1.6ms preprocess, 2185.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 19 cars, 7 trucks, 1958.8ms\n",
      "Speed: 1.5ms preprocess, 1958.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 19 cars, 7 trucks, 1997.3ms\n",
      "Speed: 1.6ms preprocess, 1997.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 17 cars, 6 trucks, 912.8ms\n",
      "Speed: 1.6ms preprocess, 912.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 6 cars, 1 truck, 1008.7ms\n",
      "Speed: 1.5ms preprocess, 1008.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 6 cars, 1 truck, 901.8ms\n",
      "Speed: 1.7ms preprocess, 901.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 886.2ms\n",
      "Speed: 1.6ms preprocess, 886.2ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 2150.7ms\n",
      "Speed: 1.8ms preprocess, 2150.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 1767.4ms\n",
      "Speed: 1.5ms preprocess, 1767.4ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 2368.8ms\n",
      "Speed: 1.6ms preprocess, 2368.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 2012.5ms\n",
      "Speed: 2.0ms preprocess, 2012.5ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 6 cars, 1 truck, 1666.1ms\n",
      "Speed: 1.6ms preprocess, 1666.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 6 cars, 1 truck, 2254.9ms\n",
      "Speed: 1.6ms preprocess, 2254.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 6 cars, 1 truck, 1106.6ms\n",
      "Speed: 1.6ms preprocess, 1106.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 3 trucks, 2 traffic lights, 909.0ms\n",
      "Speed: 1.6ms preprocess, 909.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 cars, 4 trucks, 2 traffic lights, 911.8ms\n",
      "Speed: 1.6ms preprocess, 911.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 cars, 3 trucks, 2 traffic lights, 964.6ms\n",
      "Speed: 1.5ms preprocess, 964.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 cars, 3 trucks, 2 traffic lights, 3580.3ms\n",
      "Speed: 1.9ms preprocess, 3580.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 cars, 3 trucks, 2 traffic lights, 2279.0ms\n",
      "Speed: 1.6ms preprocess, 2279.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 cars, 3 trucks, 3 traffic lights, 3057.2ms\n",
      "Speed: 1.5ms preprocess, 3057.2ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 cars, 3 trucks, 2 traffic lights, 2105.1ms\n",
      "Speed: 1.6ms preprocess, 2105.1ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 cars, 4 trucks, 2 traffic lights, 1416.9ms\n",
      "Speed: 1.8ms preprocess, 1416.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 cars, 3 trucks, 2 traffic lights, 911.3ms\n",
      "Speed: 1.5ms preprocess, 911.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 cars, 1 truck, 2 traffic lights, 912.4ms\n",
      "Speed: 1.7ms preprocess, 912.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 1 traffic light, 1 stop sign, 919.0ms\n",
      "Speed: 1.7ms preprocess, 919.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 1 traffic light, 1 stop sign, 1294.4ms\n",
      "Speed: 1.6ms preprocess, 1294.4ms inference, 6.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 2 trucks, 1 traffic light, 1 stop sign, 3764.3ms\n",
      "Speed: 1.5ms preprocess, 3764.3ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 6 cars, 1 truck, 1 traffic light, 1 stop sign, 3493.6ms\n",
      "Speed: 1.5ms preprocess, 3493.6ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 6 cars, 2 trucks, 1 traffic light, 1 stop sign, 3602.6ms\n",
      "Speed: 1.5ms preprocess, 3602.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 2 trucks, 1 traffic light, 1 stop sign, 938.1ms\n",
      "Speed: 2.2ms preprocess, 938.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 2 trucks, 1 traffic light, 1 stop sign, 911.2ms\n",
      "Speed: 1.6ms preprocess, 911.2ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x640 1 person, 5 cars, 2 trucks, 1 traffic light, 1 stop sign, 877.3ms\n",
      "Speed: 1.6ms preprocess, 877.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 1 truck, 1 traffic light, 1 stop sign, 884.0ms\n",
      "Speed: 1.6ms preprocess, 884.0ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 5 cars, 1 truck, 1 traffic light, 1 stop sign, 1969.1ms\n",
      "Speed: 1.5ms preprocess, 1969.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 2044.4ms\n",
      "Speed: 1.5ms preprocess, 2044.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 2276.7ms\n",
      "Speed: 1.5ms preprocess, 2276.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 2224.4ms\n",
      "Speed: 1.5ms preprocess, 2224.4ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 6 cars, 1 truck, 1508.7ms\n",
      "Speed: 1.7ms preprocess, 1508.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 1717.9ms\n",
      "Speed: 32.1ms preprocess, 1717.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 6 cars, 1 truck, 2177.3ms\n",
      "Speed: 1.6ms preprocess, 2177.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 6 cars, 1 truck, 1956.3ms\n",
      "Speed: 1.8ms preprocess, 1956.3ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 961.9ms\n",
      "Speed: 1.6ms preprocess, 961.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 cars, 1 truck, 1010.9ms\n",
      "Speed: 1.6ms preprocess, 1010.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 cars, 1 truck, 922.7ms\n",
      "Speed: 1.6ms preprocess, 922.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 cars, 2 trucks, 1 traffic light, 985.4ms\n",
      "Speed: 1.5ms preprocess, 985.4ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 cars, 1 truck, 1 traffic light, 2349.9ms\n",
      "Speed: 1.6ms preprocess, 2349.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 car, 2 trucks, 1 traffic light, 1499.0ms\n",
      "Speed: 1.5ms preprocess, 1499.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 3 cars, 1 truck, 1 traffic light, 1654.1ms\n",
      "Speed: 1.6ms preprocess, 1654.1ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 3 cars, 2 trucks, 1 traffic light, 1614.9ms\n",
      "Speed: 1.6ms preprocess, 1614.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 3 cars, 1 truck, 1 traffic light, 1631.3ms\n",
      "Speed: 1.5ms preprocess, 1631.3ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 cars, 1 truck, 1 traffic light, 1608.6ms\n",
      "Speed: 1.5ms preprocess, 1608.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 3 cars, 1 truck, 1 traffic light, 1565.1ms\n",
      "Speed: 4.2ms preprocess, 1565.1ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 3 cars, 1 truck, 1 traffic light, 1981.7ms\n",
      "Speed: 1.5ms preprocess, 1981.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 cars, 1 truck, 1 traffic light, 1379.4ms\n",
      "Speed: 1.5ms preprocess, 1379.4ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      " Done! Tracked video saved to: tracked_output_1.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Load model and tracker\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "input_path = \"sample_video.mp4\"\n",
    "output_path = \"tracked_output_1.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)[0]\n",
    "    dets = []\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        conf = float(box.conf[0])\n",
    "        cls = int(box.cls[0])\n",
    "        if cls == 2 and conf>0.4:  # Only class 2: car\n",
    "            dets.append(([x1, y1, x2 - x1, y2 - y1], conf, 'car'))\n",
    "\n",
    "    tracks = tracker.update_tracks(dets, frame=frame)\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Blue for cars\n",
    "        cv2.putText(frame, f'Car {track_id}', (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\" Done! Tracked video saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qd/c9103ry13rj9dp03ywh7ywc80000gn/T/ipykernel_60534/1318196443.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Run detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     def track(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprofilers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m  \u001b[0;31m# yield embedding tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         )\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/nn/autobackend.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;31m# PyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# TorchScript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;34m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;34m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;34m\"\"\"Apply bottleneck with optional shortcut connection.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ultralytics/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MODEL_PATH = \"yolov8x.pt\"  # High-accuracy YOLO model (download from ultralytics repo if needed)\n",
    "VIDEO_PATH = \"trimmed_video.mp4\"\n",
    "OUTPUT_PATH = \"tracked_output_final.mp4\"\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.3  # Lower to detect distant/small cars\n",
    "CLASS_ID_CAR = 2            # YOLOv8 class ID for 'car'\n",
    "\n",
    "# --- Load YOLOv8 model ---\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# --- Initialize DeepSORT with refined settings ---\n",
    "tracker = DeepSort(\n",
    "    max_age=40,\n",
    "    n_init=3,\n",
    "    max_cosine_distance=0.2,\n",
    "    nn_budget=100,\n",
    "    embedder=\"mobilenet\",\n",
    "    half=True\n",
    ")\n",
    "\n",
    "# --- Open input video ---\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# --- Output writer ---\n",
    "out = cv2.VideoWriter(OUTPUT_PATH, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "# --- Process each frame ---\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run detection\n",
    "    results = model(frame, verbose=False)[0]\n",
    "\n",
    "    detections = []\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        cls_id = int(box.cls[0])\n",
    "        if cls_id == CLASS_ID_CAR and conf > CONFIDENCE_THRESHOLD:\n",
    "            detections.append(([x1, y1, x2 - x1, y2 - y1], conf, \"car\"))\n",
    "\n",
    "    # Run DeepSORT tracking\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    # Draw tracks\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Car {track_id}\", (x1, y1 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\" Tracking complete. Output saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next version (Tried this one but it is not working. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'infer_worker' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import multiprocessing as mp\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import psutil\n",
    "import os\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# ---------- Video File Reader ----------\n",
    "class VideoFileReader:\n",
    "    def __init__(self, file_path):\n",
    "        self.cap = cv2.VideoCapture(file_path)\n",
    "        self.running = True\n",
    "        self.ret, self.frame = self.cap.read()\n",
    "        thread = threading.Thread(target=self.update, args=())\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "\n",
    "    def update(self):\n",
    "        while self.running and self.cap.isOpened():\n",
    "            self.ret, self.frame = self.cap.read()\n",
    "            if not self.ret:\n",
    "                self.running = False\n",
    "            time.sleep(0.01)\n",
    "\n",
    "    def read(self):\n",
    "        return self.frame.copy() if self.ret else None\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        self.cap.release()\n",
    "\n",
    "# ---------- Overlay Info ----------\n",
    "def overlay_info(frame, fps):\n",
    "    cpu = psutil.cpu_percent()\n",
    "    mem = psutil.virtual_memory().percent\n",
    "    text = f\"FPS: {fps:.1f} | CPU: {cpu}% | MEM: {mem}%\"\n",
    "    h, w = frame.shape[:2]\n",
    "    cv2.rectangle(frame, (0, h - 30), (w, h), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, text, (10, h - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5, (255, 255, 255), 1)\n",
    "    return frame\n",
    "\n",
    "# ---------- Inference Worker ----------\n",
    "def infer_worker(frame_queue, result_queue, model_path, img_size):\n",
    "    model = YOLO(model_path)\n",
    "    model.fuse()\n",
    "    tracker = DeepSort(max_age=30, n_init=3, max_cosine_distance=0.3)\n",
    "    while True:\n",
    "        item = frame_queue.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        cam_id, frame = item\n",
    "        resized = cv2.resize(frame, img_size)\n",
    "        results = model(resized, verbose=False, device='cuda' if torch.cuda.is_available() else 'cpu')[0]\n",
    "\n",
    "        detections = []\n",
    "        for box in results.boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            if cls == 2:  # Class 2 = car in COCO\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                conf = float(box.conf[0])\n",
    "                detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'car'))\n",
    "\n",
    "        tracks = tracker.update_tracks(detections, frame=resized)\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "            tid = track.track_id\n",
    "            cv2.rectangle(resized, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(resized, f'ID {tid}', (x1, y1 - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "        result_queue.put((cam_id, resized))\n",
    "\n",
    "# ---------- Main Runner ----------\n",
    "def run_multi_video_tracking(video_paths, model_path='yolov8n.pt', img_size=(640, 480), output_path='final_output.mp4'):\n",
    "    ctx = mp.get_context('spawn')\n",
    "    frame_queue = ctx.Queue()\n",
    "    result_queue = ctx.Queue()\n",
    "\n",
    "    cams = [VideoFileReader(path) for path in video_paths]\n",
    "    processes = []\n",
    "    for _ in cams:\n",
    "        p = ctx.Process(target=infer_worker, args=(frame_queue, result_queue, model_path, img_size))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    prev_time = time.time()\n",
    "    frame_count = 0\n",
    "    fps = 0\n",
    "    writer = None\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            for i, cam in enumerate(cams):\n",
    "                frame = cam.read()\n",
    "                if frame is not None:\n",
    "                    frame_queue.put((i, frame))\n",
    "\n",
    "            for _ in range(len(cams)):\n",
    "                cam_id, frame = result_queue.get()\n",
    "                annotated = overlay_info(frame, fps)\n",
    "\n",
    "                if writer is None:\n",
    "                    height, width = annotated.shape[:2]\n",
    "                    writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (width, height))\n",
    "\n",
    "                writer.write(annotated)\n",
    "                cv2.imshow(f\"Camera {cam_id}\", annotated)\n",
    "\n",
    "            frame_count += 1\n",
    "            current_time = time.time()\n",
    "            if current_time - prev_time >= 1.0:\n",
    "                fps = frame_count / (current_time - prev_time)\n",
    "                frame_count = 0\n",
    "                prev_time = current_time\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped by user\")\n",
    "\n",
    "    for cam in cams:\n",
    "        cam.stop()\n",
    "    for _ in processes:\n",
    "        frame_queue.put(None)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    if writer:\n",
    "        writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ---------- Run It ----------\n",
    "if __name__ == '__main__':\n",
    "    import multiprocessing\n",
    "    try:\n",
    "        multiprocessing.set_start_method('spawn')\n",
    "    except RuntimeError:\n",
    "        pass  # Context already set  safe to ignore\n",
    "    run_multi_video_tracking(['trimmed_video.mp4'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
